# ğŸŒ¸ Manga Translator AI ğŸŒ¸

![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-orange.svg)
![Manga-OCR](https://img.shields.io/badge/OCR-manga--ocr-ff69b4.svg)

An End-to-End AI pipeline that automatically detects, extracts, translates, and renders manga pages from Japanese to English.

## âœ¨ Pipeline Overview
1. **Object Detection:** Utilizes `Faster R-CNN` to detect Manga Frames and Speech Bubbles (Text Boxes).
2. **Reading Order Sorting:** A custom algorithm that automatically sorts the reading flow based on frame coordinates (Right-to-Left, Top-to-Bottom).
3. **OCR:** Integrates `manga-ocr` for highly accurate Japanese text extraction.
4. **Machine Translation:** Context-aware translation from Japanese to English using `deep-translator`.
5. **Rendering:** Automatically erases original text, calculates word-wrap, and seamlessly renders the translated English text back onto the original image.

---
## ğŸ‘ï¸ Demo
  ![Translation demo](./demo/demo.gif)

## ğŸ–¼ï¸ Results
| Original | Detection | Translated |
| :---: | :---: | :---: |
| ![Original](./demo/original_img.jpg) | ![Detection](./demo/detection_img.png) | ![Result](./demo/translated_img.jpg) |

## ğŸ“‚ Project Structure

```text
.
â””â”€â”€ MangaTranslator/
    â”œâ”€â”€ configs/ 
    â”‚   â””â”€â”€ faster_rcnn_default.yaml     # Configurations for data, model, and training
    â”œâ”€â”€ data/                            <-- [Git Ignored] Place your raw images and dataset here
    â”‚   â”œâ”€â”€ raw
    â”‚   â”œâ”€â”€ processed
    â”‚   â””â”€â”€ inference_data
    â”œâ”€â”€ models/                          <-- [Git Ignored] Place your downloaded .pt weights here
    â”‚   â””â”€â”€ faster_rcnn_default_weights.pt # Faster R-CNN weights (Download from Kaggle/Drive)
    â”œâ”€â”€ notebooks/
    â”‚   â””â”€â”€ test_dataset.ipynb           # Jupyter notebook for dataset exploration
    â”œâ”€â”€ outputs/                         # Directory for successfully translated images
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ data_processing/
    â”‚   â”‚   â”œâ”€â”€ cleaning_file_name.py    # Fixes corrupted file names
    â”‚   â”‚   â”œâ”€â”€ convert_xml_to_coco.py   # Converts XML annotations to COCO format
    â”‚   â”‚   â”œâ”€â”€ dataset.py               # Custom PyTorch Dataset class
    â”‚   â”‚   â””â”€â”€ split_dataset.py         # Splits data into train/val/test sets
    â”‚   â”œâ”€â”€ detection/
    â”‚   â”‚   â”œâ”€â”€ detection_model.py       # Faster R-CNN model initialization
    â”‚   â”‚   â”œâ”€â”€ test.py                  # Evaluation phase on the test dataset
    â”‚   â”‚   â”œâ”€â”€ train.py                 # Training and validation phase
    â”‚   â”‚   â””â”€â”€ utils.py                 # Helper functions
    â”‚   â”œâ”€â”€ ocr/
    â”‚   â”‚   â””â”€â”€ ocr_system.py            # manga-ocr model initialization and text extraction
    â”‚   â””â”€â”€ translation/
    â”‚       â”œâ”€â”€ renderer_system.py       # Erases old text, applies word-wrap, and draws new text
    â”‚       â””â”€â”€ translator_system.py     # Translation module using deep_translator
    â”œâ”€â”€ .gitignore                       # Ignores __pycache__, heavy weights, data, and outputs
    â”œâ”€â”€ inference.py                     # Standalone script for testing Detection + OCR
    â”œâ”€â”€ main.py                          # Main entry point for the End-to-End pipeline
    â””â”€â”€ requirements.txt                 # Libraries used
 
```

## ğŸ“Š Dataset
[Manga109s](https://huggingface.co/datasets/hal-utokyo/Manga109-s/tree/main)

## âš™ï¸ Installation
1. **Clone this repository:** 
```bash
git clone https://github.com/DungVu06/MangaTranslator.git
cd MangaTranslator
```
2. **Install the required dependencies:** 
``` bash
pip install -r requirements.txt
```
3. **Important Note on Detection Model Weights:** 
The `models/faster_rcnn_default_weights.pt` file is not included in this repository due to GitHub's file size limits. Please train the model yourself (using `src/detection/train.py`) or download the pre-trained weights and place them in the models/ directory before running the pipeline. Download link: [Google Drive](https://drive.google.com/file/d/1gzLn94gRnxJJjMBsZjFPCjoA76jD7XLp/view?usp=sharing)

## ğŸš€ Usage
1. **Quick Test**
To verify if the model correctly detects bounding boxes, reads Japanese text and translating:
``` bash
python inference.py
```
2. **Full Pipeline (End-to-End Translation)**
To run the complete process from a raw Japanese manga page to a translated English page:
``` bash
python main.py FILE-NAME
```
* Input: the image file name in main.py (e.g., `.snk_1.jpg`). Notice: Input data must be stored in `./data/input`
* Output: The fully translated and rendered image will be saved in `./outputs/output.jpg`.

## ğŸ§  Current Challenges
  * **Contextual Constraints**: The model is currently limited to extracting text exclusively within speech bubbles.
  * **Geometric Sensitivity**: Performance degrades significantly when processing non-rectangular or non-horizontal frames.
  * **Complex Scene Handling**: The system struggles with high-density action scenes, overlapping characters, or cluttered text layouts.
  * **Text Reflow Issues**: The text-wrapping logic is rudimentary, relying on fixed bounding boxes which often leads to unnatural line breaks. Text size is not flexible making it not optimized for different bubble's sizes.
  * **Rendering Artifacts**: The model struggles when a character occupies a significant portion of the speech bubble; the in-painting algorithm may inadvertently erase parts of the character's body (specifically following the text's bounding box, which results in an unnatural visual output). The text removal algorithm encounters significant difficulties when processing raw images (low-resolution or uncleaned source material).
  * **Performance Bottlenecks**: Overall execution speed is suboptimal due to the overhead of the Faster R-CNN architecture and external API latency. (~8s/img)
  * **Layout Sequencing**: The sorting algorithm fails to correctly sequence text when processing double-page spreads (two pages per image) instead of individual pages.
  
## ğŸ†™ Version History
* **v1.0.0:**
  * Successfully implemented a functional end-to-end pipeline; however, latency remains a significant bottleneck.
  * Core components, including Object Detection (Faster R-CNN), OCR, Translation, and Rendering, are operational and meet basic requirements.
* **v1.0.1:**
  * Updated demo in README.md using Gradio
* **v1.1.0:**
  * Better colors and cleaner text removal in the final translated images.
  * Minor updates to make running main.py and inference.py easier.
  * Update new font.
* **v1.2.0 (Current):**
  * Update new text wrapping/size algorithms for faster and more accurate translated text!


## ğŸ™ Thanks for Watching
If you find this project interesting or useful, feel free to â­ star the repository and share your feedback.
Contributions and suggestions are always welcome!

I'm Yorha. Built with love for AI and Manga! ğŸğŸ
